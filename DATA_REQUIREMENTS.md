# PPI-HGCN æ•°æ®éœ€æ±‚è¯¦ç»†è¯´æ˜

## ğŸ“Š æ•°æ®æ¦‚è§ˆ

æ‚¨çš„PPI-HGCNé¡¹ç›®éœ€è¦ä»¥ä¸‹å‡ ç±»æ•°æ®ï¼Œæ€»å­˜å‚¨ç©ºé—´éœ€æ±‚çº¦ **50-80GB**

## ğŸ—ƒï¸ è¯¦ç»†æ•°æ®éœ€æ±‚

### 1. STRINGæ•°æ®åº“ (æ ¸å¿ƒæ•°æ®æº)
**ç”¨é€”**: è›‹ç™½è´¨ç›¸äº’ä½œç”¨ç½‘ç»œæ•°æ®
**å¤§å°**: ~25-30GB (å‹ç¼©å ~8-10GB)

#### æ¶‰åŠç‰©ç§:
- **Human (äººç±»)**: taxid=9606
- **Mouse (é¼ )**: taxid=10090
- **Yeast (é…µæ¯)**: taxid=4932

#### æ¯ä¸ªç‰©ç§éœ€è¦4ç±»æ–‡ä»¶:
```bash
# ä¾‹å¦‚äººç±» (9606)
9606.protein.physical.links.v12.0.txt.gz    # ~200-500MB ç›¸äº’ä½œç”¨æ•°æ®
9606.protein.info.v12.0.txt.gz              # ~50-100MB  è›‹ç™½è´¨åŸºæœ¬ä¿¡æ¯
9606.protein.aliases.v12.0.txt.gz           # ~100-200MB IDæ˜ å°„åˆ«å
9606.protein.sequences.v12.0.fa.gz          # ~200-800MB è›‹ç™½è´¨åºåˆ—
```

**è¯¦ç»†å¤§å°ä¼°ç®—**:
- **Human**: ~1.5-2GB (è§£å‹å ~4-6GB)
- **Mouse**: ~1-1.5GB (è§£å‹å ~3-4GB)
- **Yeast**: ~200-500MB (è§£å‹å ~800MB-1.5GB)

### 2. HuRIæ•°æ® (Human Reference Interactome)
**ç”¨é€”**: é«˜è´¨é‡äººç±»è›‹ç™½è´¨ç›¸äº’ä½œç”¨è®­ç»ƒé›†
**å¤§å°**: ~100-200MB

```bash
data/raw/huri/
â”œâ”€â”€ HuRI_binaryPPI.tsv          # ~50MB   äºŒå…ƒç›¸äº’ä½œç”¨æ•°æ®
â””â”€â”€ HuRI_sequences.fasta        # ~100MB  å¯¹åº”è›‹ç™½è´¨åºåˆ—
```

**æ•°æ®è§„æ¨¡**:
- è›‹ç™½è´¨æ•°é‡: ~17,000ä¸ª
- ç›¸äº’ä½œç”¨: ~53,000æ¡
- å¹³å‡åº¦æ•°: ~6.2

### 3. UniProt IDæ˜ å°„æ•°æ®
**ç”¨é€”**: ä¸åŒè›‹ç™½è´¨IDä½“ç³»é—´çš„æ˜ å°„
**å¤§å°**: ~500MB-1GB

```bash
data/raw/mapping/
â”œâ”€â”€ huri_uniprot_mapping.tsv    # ~50MB   HuRIåˆ°UniProtæ˜ å°„
â”œâ”€â”€ string_uniprot_mapping.tsv  # ~200MB  STRINGåˆ°UniProtæ˜ å°„
â””â”€â”€ id_mapping_cache.pkl        # ~100MB  æ˜ å°„ç¼“å­˜
```

### 4. ESM-2è›‹ç™½è´¨ç‰¹å¾ (æœ€å¤§æ•°æ®é‡)
**ç”¨é€”**: é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹æå–çš„è›‹ç™½è´¨åºåˆ—ç‰¹å¾
**å¤§å°**: ~20-40GB

```bash
features/esm2_650m/
â”œâ”€â”€ human/
â”‚   â”œâ”€â”€ embeddings_batch_0000.pt     # æ¯ä¸ªæ–‡ä»¶ ~100-500MB
â”‚   â”œâ”€â”€ embeddings_batch_0001.pt
â”‚   â””â”€â”€ ...                          # æ€»è®¡ ~15-25GB
â”œâ”€â”€ mouse/
â”‚   â””â”€â”€ ...                          # ~8-12GB
â”œâ”€â”€ yeast/
â”‚   â””â”€â”€ ...                          # ~2-3GB
â””â”€â”€ metadata/
    â”œâ”€â”€ protein_lengths.json         # ~10MB
    â””â”€â”€ batch_info.json              # ~5MB
```

**ç‰¹å¾ç»´åº¦**: 1280ç»´ (ESM-2 650Mæ¨¡å‹)
**å­˜å‚¨æ ¼å¼**: PyTorchå¼ é‡ (.ptæ–‡ä»¶)

### 5. å¤„ç†åçš„å›¾æ•°æ®
**ç”¨é€”**: æ„å»ºå¥½çš„PyTorch Geometricå›¾å¯¹è±¡
**å¤§å°**: ~5-10GB

```bash
data/processed/
â”œâ”€â”€ human_graph.pt               # ~2-3GB   äººç±»PPIç½‘ç»œ
â”œâ”€â”€ mouse_graph.pt               # ~1-2GB   é¼ PPIç½‘ç»œ
â”œâ”€â”€ yeast_graph.pt               # ~200-500MB é…µæ¯PPIç½‘ç»œ
â”œâ”€â”€ human_node_mapping.json      # ~50MB    èŠ‚ç‚¹IDæ˜ å°„
â”œâ”€â”€ mouse_node_mapping.json      # ~30MB
â”œâ”€â”€ yeast_node_mapping.json      # ~10MB
â””â”€â”€ preprocessing_stats.json     # ~1MB     é¢„å¤„ç†ç»Ÿè®¡
```

### 6. æ¨¡å‹å’Œæ—¥å¿—æ•°æ®
**ç”¨é€”**: è®­ç»ƒæ£€æŸ¥ç‚¹å’Œå®éªŒè®°å½•
**å¤§å°**: ~2-5GB

```bash
checkpoints/
â”œâ”€â”€ hgcn_epoch_050.pt           # ~100-200MB æ¯ä¸ªcheckpoint
â”œâ”€â”€ hgcn_epoch_100.pt
â””â”€â”€ best_model.pt

logs/
â”œâ”€â”€ train_eval.log              # ~50-100MB è®­ç»ƒæ—¥å¿—
â”œâ”€â”€ tensorboard/                # ~500MB    TensorBoardæ—¥å¿—
â””â”€â”€ wandb/                      # ~200MB    W&Bç¼“å­˜

results/
â”œâ”€â”€ evaluation_results.json     # ~10MB     è¯„ä¼°ç»“æœ
â”œâ”€â”€ ablation_study/             # ~100MB    æ¶ˆèå®éªŒ
â””â”€â”€ visualizations/             # ~200MB    å¯è§†åŒ–ç»“æœ
```

## ğŸ”„ æ•°æ®è·å–æµç¨‹

### è‡ªåŠ¨ä¸‹è½½æ•°æ® (~8-10GB)
```bash
# 1. ä¸‹è½½STRINGæ•°æ® (è‡ªåŠ¨)
bash scripts/00_download_string.sh
# ä¸‹è½½æ—¶é—´: 1-3å°æ—¶ (å–å†³äºç½‘ç»œ)

# 2. UniProt IDæ˜ å°„ (è‡ªåŠ¨)
python scripts/01_uniprot_id_mapping.py
# å¤„ç†æ—¶é—´: 30-60åˆ†é’Ÿ
```

### æ‰‹åŠ¨è·å–æ•°æ®
**HuRIæ•°æ®** (éœ€æ‰‹åŠ¨ä¸‹è½½):
- è®¿é—®: http://www.interactome-atlas.org/download
- ä¸‹è½½: HuRI Binary PPI dataset
- æ”¾ç½®: `data/raw/huri/`

### ç‰¹å¾æå– (~20-40GB)
```bash
# ESM-2ç‰¹å¾æå– (æœ€è€—æ—¶)
bash scripts/03_extract_esm650m.sh
# æå–æ—¶é—´:
# - CPU: 10-20å°æ—¶
# - GPU (16GB+): 3-6å°æ—¶
```

## ğŸ’¾ å­˜å‚¨ç©ºé—´å»ºè®®

### æœ€ä½é…ç½®
- **SSD**: 100GB (ç”¨äºæ´»è·ƒæ•°æ®å’Œæ¨¡å‹)
- **HDD**: 200GB (ç”¨äºåŸå§‹æ•°æ®å­˜å‚¨)

### æ¨èé…ç½®
- **NVMe SSD**: 200GB (ç³»ç»Ÿ+æ´»è·ƒæ•°æ®+ç‰¹å¾)
- **SATA SSD/HDD**: 500GB (åŸå§‹æ•°æ®+å¤‡ä»½)

### ç†æƒ³é…ç½®
- **NVMe SSD**: 500GB+ (å…¨éƒ¨æ•°æ®åœ¨é«˜é€Ÿå­˜å‚¨)
- **ç½‘ç»œå­˜å‚¨**: 1TB+ (æ•°æ®å¤‡ä»½å’Œå½’æ¡£)

## âš¡ ä¼˜åŒ–å»ºè®®

### 1. å­˜å‚¨ä¼˜åŒ–
```bash
# ä½¿ç”¨å‹ç¼©å­˜å‚¨èŠ‚çœ50%ç©ºé—´
tar -czf string_data_backup.tar.gz data/raw/string/
rm -rf data/raw/string/  # åŸå§‹æ–‡ä»¶

# ç‰¹å¾æ–‡ä»¶å‹ç¼©
python -c "
import torch
features = torch.load('features/large_file.pt')
torch.save(features, 'features/large_file_compressed.pt', _use_new_zipfile_serialization=True)
"
```

### 2. ä¸‹è½½ä¼˜åŒ–
```bash
# å¹¶è¡Œä¸‹è½½åŠ é€Ÿ
export DOWNLOAD_THREADS=4
bash scripts/00_download_string.sh --parallel
```

### 3. å†…å­˜æ˜ å°„(å¤§æ•°æ®é›†)
```python
# ä½¿ç”¨å†…å­˜æ˜ å°„å‡å°‘RAMå ç”¨
dataset = torch.utils.data.TensorDataset(
    torch.from_file('features.dat', shared=True, size=total_size)
)
```

## ğŸš¨ æ³¨æ„äº‹é¡¹

### ç½‘ç»œè¦æ±‚
- **å¸¦å®½**: â‰¥50Mbps (ä¸‹è½½æ—¶é—´3-6å°æ—¶)
- **æµé‡**: ~10GB åˆæ¬¡ä¸‹è½½
- **ç¨³å®šæ€§**: æ”¯æŒæ–­ç‚¹ç»­ä¼ 

### è®¸å¯è¯
- **STRING**: å­¦æœ¯å…è´¹,å•†ä¸šéœ€æˆæƒ
- **HuRI**: CC BY 4.0è®¸å¯
- **UniProt**: CC BY 4.0è®¸å¯
- **ESM-2**: MITè®¸å¯

### æ•°æ®æ›´æ–°
- **STRING**: å¹´åº¦æ›´æ–° (å»ºè®®åŠå¹´æ£€æŸ¥)
- **HuRI**: ä¸å®šæœŸæ›´æ–°
- **æ¨¡å‹ç‰¹å¾**: ä¸€æ¬¡æå–é•¿æœŸä½¿ç”¨

## ğŸ“ˆ æ•°æ®ç»Ÿè®¡

| æ•°æ®ç±»å‹ | å‹ç¼©å¤§å° | è§£å‹å¤§å° | æ–‡ä»¶æ•°é‡ | æ›´æ–°é¢‘ç‡ |
|---------|---------|---------|---------|---------|
| STRINGåŸå§‹ | ~8GB | ~25GB | ~36ä¸ª | å¹´åº¦ |
| HuRI | ~150MB | ~150MB | 2ä¸ª | ä¸å®šæœŸ |
| IDæ˜ å°„ | ~300MB | ~800MB | ~10ä¸ª | å­£åº¦ |
| ESM-2ç‰¹å¾ | ~15GB | ~35GB | ~200ä¸ª | ä¸€æ¬¡æ€§ |
| å¤„ç†å›¾ | ~3GB | ~8GB | ~20ä¸ª | é‡å¤„ç† |
| **æ€»è®¡** | **~26GB** | **~69GB** | **~268ä¸ª** | - |

---

**å»ºè®®**: é¦–æ¬¡éƒ¨ç½²é¢„ç•™ **100GB** å­˜å‚¨ç©ºé—´,ç”Ÿäº§ç¯å¢ƒå»ºè®® **200GB+** ä»¥æ”¯æŒå¤šå®éªŒå¹¶è¡Œã€‚
